{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49a2748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Flowchart saved at /demo_assets/pipeline_flowchart.png\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import os\n",
    "\n",
    "\n",
    "# --- Create a flowchart ---\n",
    "dot = Digraph(comment=\"Pipeline Flowchart\")\n",
    "\n",
    "dot.attr(rankdir='TB', size='8,5')\n",
    "\n",
    "# Nodes\n",
    "dot.node('A', 'Upload Data')\n",
    "dot.node('B', 'Preprocessing')\n",
    "dot.node('C', 'Train Model')\n",
    "dot.node('D', 'Evaluate Model')\n",
    "dot.node('E', 'Visualize Results\\n(GradCAM & SHAP)')\n",
    "dot.node('F', 'Download Reports')\n",
    "\n",
    "# Edges\n",
    "dot.edges(['AB', 'BC', 'CD', 'DE', 'EF'])\n",
    "\n",
    "# Save the flowchart\n",
    "dot.render('demo_assets/pipeline_flowchart', format='png', cleanup=True)\n",
    "\n",
    "print(\"✅ Flowchart saved at /demo_assets/pipeline_flowchart.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0ee097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved demo_assets/sample_raw1.png\n",
      "✅ Saved demo_assets/sample_tile1.png\n",
      "✅ Saved demo_assets/sample_processed_tile1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frank\\lymphoid_malignancy_project\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\frank\\lymphoid_malignancy_project\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\frank\\lymphoid_malignancy_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GradCAM saved to demo_assets/sample_gradcam_output.png\n",
      "❌ Failed to copy SHAP plot: [Errno 2] No such file or directory: 'C:\\\\Users\\\\frank\\\\lymphoid_malignancy_project\\\\outputs\\\\shap_summary.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_13752\\651214457.py:84: RuntimeWarning: invalid value encountered in cast\n",
      "  heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import sys\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")  \n",
    "from gradcam_utils import GradCAM\n",
    "\n",
    "\n",
    "# Ensure access to scripts/\n",
    "sys.path.append(\"../scripts\")\n",
    "from gradcam_utils import GradCAM\n",
    "\n",
    "# --- Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs(\"demo_assets\", exist_ok=True)\n",
    "\n",
    "# --- 1. Copy a Sample Raw Image (WSI simulation) ---\n",
    "raw_src = r\"C:\\Users\\frank\\lymphoid_malignancy_project\\data\\raw\\CLL\\sj-03-476_001.tif\"\n",
    "raw_dst = \"demo_assets/sample_raw1.png\"\n",
    "with Image.open(raw_src) as img:\n",
    "    img.thumbnail((800, 800))\n",
    "    img.save(raw_dst)\n",
    "print(\"✅ Saved demo_assets/sample_raw1.png\")\n",
    "\n",
    "# --- 2. Copy a Sample Tile Image ---\n",
    "tile_src = r\"C:\\Users\\frank\\lymphoid_malignancy_project\\data\\tiles\\CLL\\tile_0_x0_y0.png\"\n",
    "tile_dst = \"demo_assets/sample_tile1.png\"\n",
    "shutil.copy(tile_src, tile_dst)\n",
    "print(\"✅ Saved demo_assets/sample_tile1.png\")\n",
    "\n",
    "# --- 3. Copy + Resize Preprocessed Tile Image ---\n",
    "processed_src = r\"C:\\Users\\frank\\lymphoid_malignancy_project\\data\\processed_tiles\\CLL\\tile_0_x0_y0_aug0.png\"\n",
    "processed_dst = \"demo_assets/sample_processed_tile1.png\"\n",
    "with Image.open(processed_src) as img:\n",
    "    img_resized = img.resize((224, 224))\n",
    "    img_resized.save(processed_dst)\n",
    "print(\"✅ Saved demo_assets/sample_processed_tile1.png\")\n",
    "\n",
    "# --- 4. GradCAM ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "input_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "# --- Load Sample Image (Preprocessed Tile) ---\n",
    "tile_path = r\"C:\\Users\\frank\\lymphoid_malignancy_project\\data\\processed_tiles\\CLL\\tile_0_x0_y0_aug0.png\"\n",
    "img = Image.open(tile_path).convert(\"RGB\")\n",
    "img_resized = img.resize((224, 224))  # <-- This is now defined\n",
    "img_resized.save(\"demo_assets/sample_processed_tile1.png\")\n",
    "\n",
    "# --- Preprocess ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "input_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "# --- Load ResNet50 Model ---\n",
    "model_path = r\"C:\\Users\\frank\\lymphoid_malignancy_project\\data\\models\\trained_resnet50.pth\"\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 3)  # Adjust to match your class count\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- Generate GradCAM ---\n",
    "try:\n",
    "    target_layer = model.layer4[1].conv2  # Works for ResNet50 too\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    heatmap = gradcam.generate(input_tensor)\n",
    "\n",
    "    img_np = np.array(img_resized)\n",
    "    heatmap_resized = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap_color * 0.4 + img_np\n",
    "\n",
    "    gradcam_out = Image.fromarray(superimposed_img.astype(np.uint8))\n",
    "    gradcam_out.save(\"demo_assets/sample_gradcam_output.png\")\n",
    "    print(\"✅ GradCAM saved to demo_assets/sample_gradcam_output.png\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ GradCAM failed:\", e)\n",
    "\n",
    "# --- Copy SHAP Summary Plot ---\n",
    "shap_source = r\"C:\\Users\\frank\\lymphoid_malignancy_project\\outputs\\shap_summary.png\"\n",
    "shap_dest = \"demo_assets/sample_shap_summary.png\"\n",
    "\n",
    "try:\n",
    "    shutil.copy(shap_source, shap_dest)\n",
    "    print(\"✅ SHAP summary plot copied to demo_assets/sample_shap_summary.png\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Failed to copy SHAP plot:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
